# k6 시나리오

- 하나의 코드에서 여러 시나리오를 작성 가능, 각 시나리오는 독립적으로 실행도 가능
- 각각의 시나리오는 별도의 VU와 iteration 스케쥴링 패턴을 사용할 수 있음
- 시나리오는 서로 독립적이고 병렬로 수행할 수 있다. `startTime` 옵션값을 통해 순차적으로 수행되는 것처럼 보이게 할 수 있다.
- 시나리오마다 다른 환경 변수와 metric 태그를 설정할 수 있다.


## 시나리오 설정하기

```js
export const options = {
  scenarios: {
    example_scenario: {
      // (required) name of the executor to use 
      executor: 'shared-iterations',

      // common scenario configuration
      startTime: '10s',
      gracefulStop: '5s',
      env: { EXAMPLEVAR: 'testing' },
      tags: { example_tag: 'testing' },

      // executor-specific configuration
      vus: 10,
      iterations: 200,
      maxDuration: '10s',
    },
    another_scenario: {
      /*...*/
    },
  },
};
```


## Scenario executors

각 k6 시나리오의 VU workload는 executor에 의해 스케쥴링된다.        
Executors는 테스트를 얼마나 오래 실행할지, 트래픽을 일관적으로 수행할지 변경할지, 또는 workload를 VU로 모델링할지 arrival rate로 모델링할지 설정할 수 있다.

## exceutor 설정 선택지

- number of iterations
    - `shared-iterations`: VU 간 iteration을 공유한다
    - `per-vu-iterations`: 각 VU는 설정된 iteration 만큼 수행한다.
- number of VUs
    - `constant-VUs`: VUs를 일정한 개수만큼 보낸다
    - `ramping-vus`: VU의 개수를 설정된 stage에 따라 늘렸다 줄일 수 있다.
- iteration rate
    - `constant-arrival-rate`: 일정한 arrival rate에 맞춰서 iteration을 수행한다. ex) 1초에 10개씩 요청. VU의 개수는 iteration이 정해진 시간보다 늦게 끝날수록 더 많은 VU가 필요해진다.
    - `ramping-arrival-rate`: arrival rate를 stage마다 설정할 수 있다.


## 예시

> 아래 예시는 두 시나리오를 포함한다.
> 1. `shared_iter_scenario` 시나리오: `shared-iterations` executor 사용. 테스트 시작 즉시 실행되며, 100개의 iteration을 최대한 빨리 도는 것이 목표다. 일부 VU가 다른 VU보다 더 많은  iteration을 돌 수 있다.
> 2.  `per_vu_scenario` 시나리오: `per-vu-iterations` executor 사용. 테스트 시작 10초 후 실행된다. 10개의 VU가 10번 iteration을 돈다. 

### 예제 코드

```js
import http from 'k6/http';

export const options = {
  scenarios: {
    shared_iter_scenario: {
      executor: 'shared-iterations',
      vus: 10,
      iterations: 100,
      startTime: '0s',
    },
    per_vu_scenario: {
      executor: 'per-vu-iterations',
      vus: 10,
      iterations: 10,
      startTime: '10s',
    },
  },
};

export default function () {
  http.get('https://test.k6.io/');
}
```

### 실행 결과

```sh
 docker run --rm --network prometheus_k6 -e K6_PROMETHEUS_RW_SERVER_URL=http://prometheus:9090/api/v1/write -e K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM=true -i grafana/k6 run -o experimental-prometheus-rw --tag testid=$(date "+%Y%m%d-%H%M%S")  - <k6-scripts/scenario1.js            

          /\      |‾‾| /‾‾/   /‾‾/   
     /\  /  \     |  |/  /   /  /    
    /  \/    \    |     (   /   ‾‾\  
   /          \   |  |\  \ |  (‾)  | 
  / __________ \  |__| \__\ \_____/ .io

     execution: local
        script: -
        output: Prometheus remote write (http://prometheus:9090/api/v1/write)

     scenarios: (100.00%) 2 scenarios, 20 max VUs, 10m40s max duration (incl. graceful stop):
              * shared_iter_scenario: 100 iterations shared among 10 VUs (maxDuration: 10m0s, gracefulStop: 30s)
              * per_vu_scenario: 10 iterations for each of 10 VUs (maxDuration: 10m0s, startTime: 10s, gracefulStop: 30s)


running (00m01.0s), 10/20 VUs, 18 complete and 0 interrupted iterations
shared_iter_scenario   [  18% ] 10 VUs   00m01.0s/10m0s  018/100 shared iters
per_vu_scenario      • [   0% ] waiting  09.0s          

running (00m02.0s), 10/20 VUs, 67 complete and 0 interrupted iterations
shared_iter_scenario   [  67% ] 10 VUs   00m02.0s/10m0s  067/100 shared iters
per_vu_scenario      • [   0% ] waiting  08.0s          

running (00m03.0s), 00/20 VUs, 100 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs   00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      • [   0% ] waiting  07.0s          

running (00m04.0s), 00/20 VUs, 100 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs   00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      • [   0% ] waiting  06.0s          

running (00m05.0s), 00/20 VUs, 100 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs   00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      • [   0% ] waiting  05.0s          

running (00m06.0s), 00/20 VUs, 100 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs   00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      • [   0% ] waiting  04.0s          

running (00m07.0s), 00/20 VUs, 100 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs   00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      • [   0% ] waiting  03.0s          

running (00m08.0s), 00/20 VUs, 100 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs   00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      • [   0% ] waiting  02.0s          

running (00m09.0s), 00/20 VUs, 100 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs   00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      • [   0% ] waiting  01.0s          

running (00m10.0s), 00/20 VUs, 100 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs   00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      • [   0% ] waiting  00.0s          

running (00m11.0s), 10/20 VUs, 120 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs  00m02.7s/10m0s  100/100 shared iters
per_vu_scenario        [  20% ] 10 VUs  00m01.0s/10m0s  020/100 iters, 10 per VU

running (00m12.0s), 10/20 VUs, 168 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs  00m02.7s/10m0s  100/100 shared iters
per_vu_scenario        [  68% ] 10 VUs  00m02.0s/10m0s  068/100 iters, 10 per VU

     data_received..................: 2.4 MB 190 kB/s
     data_sent......................: 27 kB  2.1 kB/s
     http_req_blocked...............: avg=49.52ms  min=1.93µs   med=3.19µs   max=604.2ms  p(90)=39.97ms  p(95)=454.39ms
     http_req_connecting............: avg=20.86ms  min=0s       med=0s       max=227.6ms  p(90)=19.64ms  p(95)=203.95ms
     http_req_duration..............: avg=206.8ms  min=195.78ms med=202.02ms max=229.6ms  p(90)=222.71ms p(95)=225.1ms 
       { expected_response:true }...: avg=206.8ms  min=195.78ms med=202.02ms max=229.6ms  p(90)=222.71ms p(95)=225.1ms 
     http_req_failed................: 0.00%  ✓ 0        ✗ 200 
     http_req_receiving.............: avg=155.08µs min=41.58µs  med=122.92µs max=1.62ms   p(90)=259.65µs p(95)=316.76µs
     http_req_sending...............: avg=20.96µs  min=8.36µs   med=14.06µs  max=299.48µs p(90)=31.3µs   p(95)=52.92µs 
     http_req_tls_handshaking.......: avg=20.69ms  min=0s       med=0s       max=223.04ms p(90)=19.68ms  p(95)=202.42ms
     http_req_waiting...............: avg=206.62ms min=195.57ms med=201.94ms max=229.49ms p(90)=222.58ms p(95)=225.01ms
     http_reqs......................: 200    15.79251/s
     iteration_duration.............: avg=256.5ms  min=195.9ms  med=203.09ms max=829.45ms p(90)=266.6ms  p(95)=677.11ms
     iterations.....................: 200    15.79251/s
     vus............................: 10     min=0      max=10
     vus_max........................: 20     min=20     max=20


running (00m12.7s), 00/20 VUs, 200 complete and 0 interrupted iterations
shared_iter_scenario ✓ [ 100% ] 10 VUs  00m02.7s/10m0s  100/100 shared iters
per_vu_scenario      ✓ [ 100% ] 10 VUs  00m02.7s/10m0s  100/100 iters, 10 per VU
```




## 시나리오에서 사용되는 여러 개념들

### Open and Closed models

#### Closed models

> 참고)   
> arrival rate: 얼마나 새로운 요청이 도착하는지. throughput   
>  - e.g. requests per second

각 iteration의 수행 시간이 테스트에서 실행되는 iteration의 개수를 결정한다. 다음 iteration은 이전 iteration이 끝나기 전에 시작되지 않는다.
- 새 VU iteration의 start rate나 arrival rate가 iteration duration과 tightly coupled 되어있다.
    - vus=1, duration=1m로 6초 걸리는 API에 요청을 보내면, 테스트 수행 동안 총 10번의 iteration만 수행한다.
- 단점: _Coordinated omission_ problem
    - VU iteration의 duration이 새 VU iteration의 시작과 강하게 결합되어 있어서, SUT의 response time이 테스트의 throughput에 영향을 준다. response time이 느려지는 것은 iteration이 길어지고, 새 iteration의 arrival rate이 낮아지는 것을 의미한다.
    - SUT가 stressed되어서 응답 속도가 느려지게 되면, closed model 부하 테스트는 기다릴 것이고, iteration duration이 길어지고, 새 VU iteration의 arriaval rate가 점점 줄어들 것이다.
    - 특정 arraival rate(throughput)을 시뮬레이팅할 때 ideal 하지 않다. 
    - [RedHat performance team의 Coordinated Omission 관련 블로그 글](https://redhatperf.github.io/post/coordinated-omission/)
        - Coordinated Omission is the unintended back pressure a system under test can apply to a load generation tool, that prevents that tool for accurately recording user experience.
        - Response time = wait time + service time 이라는 것을 꼭 기억해야 한다. Wait time을 누락하고 service time만 기록해서는 안된다. wait time은 상당할 수 있고 summary statistics에 큰 영향을 미칠 수 있다.



#### Open models

Iteration 수행 시간에서 VU iteration 개수를 decouple한다. SUT의 응답 시간이 SUT에 주어지는 load에 영향을 주지 않는다.

<img src="https://grafana.com/media/docs/k6-oss/arrival-rate-open-closed-model.png" width="500">

k6는 open model 구현을 위해 두 가지 executor를 제공한다.
- `constant-arrival-rate`
- `ramping-arrival-rate`

각 executor에 대한 자세한 내용은 Executors 문서를 참고하기.


### Arrival-rate VU allocation

Arrival-rate executors는 가용한 VU가 있는 한, target rate에 맞춰 iteration을 수행한다.   
따라서, VU를 충분히 사전 할당해줘야한다. 즉, 테스트를 돌리기 전에
- 부하를 설정하고 (new iteraions per unit of time)
- 충분한 VU를 할당했는지 확인해야 한다.

Open model 시나리오에서, arrival-rate executor는 설정된 rate에 따라 iteration을 시작한다. Closed model 시나리오에서는 VU가 iteration이 끝날 때까지 기다렸다가 다음 iteration을 실행해야 한다.
- ex) arrival-rate executors는 매 초 10개의 iterations를 실행하도록 할 수 있다.

각 iteration은 실행되려면 하나의 VU가 필요하다. K6의 VU는 싱글쓰레드이기 때문에 (다른 javascript runtime과 같이..) VU 하나는 한 번에 하나의 iteration만 돌릴 수 있다. 따라서, 충분한 수의 VU를 사전할당해줘야 한다.
- ex) 시나리오가 rate=10, timeUnit=1m이면, 매 6초마다 새 iteration을 실행한다. 이 때, target iteration rate를 시작할 수 있는지 여부는 할당된 VU가 충분한지에 따라 다르다.

실제로, 적절한 VU 값을 결정하는 것은 시행착오가 있을 수 있다. 

#### K6가 VU를 할당하는 방법

Arrival-rate 시나리오를 시작하기 전에, k6는 `preAllocatedVUs`만큼 VU를 초기화한다. 테스트를 수행하면서, 가용한 preAllocatedVUs의 개수가 실제 k6가 얼마나 많은 iteration을 시작할 수 있는지를 결정한다. 

1. VU가 충분할 때: extra VU는 idle 상태가 된다. 핑료 시 사용될 준비가 되어 있음.
2. VU가 부족할 때: 실행할 수 없는 iterations에 대해 `dropped_iterations` metric을 만든다.


#### 필수 allocation VU 개수에 Iteration duration이 영향을 미친다.

duration이 길수록 VU는 더 많이 필요하다.
- 매 초 요청을 보내야 하는데, N초에 요청을 보낸 VU의 iteration이 아직 종료되지 않았다면 N+1초에 요청을 보낼 때는 다른 VU를 사용해야 하기 때문.

이상적인 사전 할당 VU 개수
```sh
preAllocatedVUs = [median_iteration_duration * rate] + constant_for_variance
```


#### maxVUs는 설정하지 않는 것을 권장한다

`arrival-rate` executor는 `maxVUs` 속성이 있어서, 설정하면 아래처럼 동작한다.
1. `preAllocatedVUs` 만큼 VU를 사전 할당한다.
2. target iteration rate로 테스트를 수행한다.
3. target이 가용 VU 개수를 넘으면 또 다른 VU를 할당한다.
4. target이 여전히 가용 VU 개수를 넘으면 `maxVUs` 까지 VU를 새로 할당한다.

이 방법은 편해보이지만, 사용하지는 마라.
VU 할당은 CPU와 메모리 비용이고, 테스트를 수행하면서 VU을 새로 할당하는 것은 부하 생성기에 과부하가 걸리고 테스트 결과가 왜곡될 수 있다.

`maxVUs`를 사용해도 되는 케이스:
1. 초기 테스트에서 할당할 VU 개수를 측정할 때
2. 사전할당한 VU 개수에 약간의 쿠션을 줄 때


### Dropped iterations

어떤 시나리오에서는 기대했던 만큼 많은 iteration을 수행할 수 없을 수도 있다. k6는 `dropped_iterations` 이라는 metric으로 이 수치를 추적한다.   

Dropped iterations이 발생하는 케이스:
1. executor 설정 문제
2. SUT가 VU arrival rate를 처리하지 못할 때

#### executor 설정 문제

executor 에 따라 원인이 다름.
- `shared-iterations`, `per-vu-iterations`: 모든 iteration이 끝나기 전에 `maxDuration`에 도달한 경우 iteration이 drop된다. 이 경우에는 `maxDuration` 설정을 늘려주면 된다.
- `constant-arrival-rate`, `ramping-arrival-rate`: 가용한 VU가 없을 경우 iteration이 drop된다. 테스트 초반에 발생하면 사전 할당할 VU 개수를 늘리면 된다. 테스트 후반에 발생하면 SUT의 처리 성능이 떨어져서 iteration duration이 갈수록 길어지기 때문에 발생하는 것이다.


#### SUT가 VU arrival rate를 처리하지 못할 때

latency가 길어지거나 iteration duration이 길어지는 어느 순간이 되면, k6는 설정된 arrival rate를 보낼 수 있는 가용 VU가 더 이상 없는 상황이 된다. ==> iteration drop이 발생한다.

- SUT의 response가 너무 길어서 k6가 예정된 iteraion을 큐에서 드랍한다
- SUT의 iteration duration이 너무 길어져서 k6가 target arrival rate를 맞추지 못할 것 같으면 더 많은 VU를 스케쥴링해야 하게 된다.
- 짧은 네트워크 문제일 수도 있다.

threshold에 `dropped_iterations`을 설정하는 것을 권장한다.



### Graceful stop


`gracefulStop`는 테스트 끝에 진행 중인 iteration을 끝낼 수 있는 시간이다.    
테스트가 duration이나 ramp down 설정이 있으면, k6가 진행 중인 iteration을 interrupt할 수 있다. 이렇게 interrupt하는 경우 테스트 결과가 skewed되거나 예상치못한 결과가 나올 수 있다.     
=> 이걸 해결하기 위해 `gracefulStop`를 설정할 수 있다.

#### `gracefulStop`

k6가 iteration을 강제로 interrup하기 전 기다리는 시간을 설정할 수 있음.

#### `gracefulRampDown`

`ramping-vus` executor는 `gracefulRampDown` 옵션을 사용할 수 있다.
뭔지 잘 모르겠다.